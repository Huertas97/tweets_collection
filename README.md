![GitHub language count](https://img.shields.io/github/languages/count/Huertas97/tweets_collection?style=plastic) ![GitHub repo size](https://img.shields.io/github/repo-size/Huertas97/tweets_collection?style=plastic) ![GitHub watchers](https://img.shields.io/github/watchers/Huertas97/tweets_collection?style=social)

# **Autor** 
Álvaro Huertas García

# Índice
 
 * [Information](#information)
 * [Usage](#usage)


![](https://mermaid.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)


# **Information** 

Repository where tweets extracted from various Twitter accounts and hastags (total 200) are stored from October 1, 2020. The tweets extracted from the previous day are added daily. Although no content filter is applied to the extracted tweets (e.g. the term COVID-19 is not required to appear in the tweet), the hastags and accounts have been manually selected depending on whether their content fits the current COVID-19 health emergency situation. Feel free to add or change the Twitter accounts.  

The extracted tweets are organized by date (day) and by user or hastags. The extracted tweets are locally saved in json format and uploaded to GitHub as txt files only with the tweet ids (dehydrated). Accounts without tweets do not create any json file. The information in the json files is:

 * account name
 * tweet id
 * full text (both tweet and retweet)
 * verification of the account
 * tweet date creation
 * fecha de creación del tweet
 * nº of times retweeted
 * favourites count
 * tweet location (if available)
 * account url 
 * tweet entities (url, hastags, etc)


# Usage

First step is to clone the repository: 
`$ git clone https://github.com/Huertas97/tweets_collection.git`

Or download only the file Tweet_wrapper_v2.py if you want to extract only tweets. The accounts used for extracting the tweets can be modified in this code. 
Once downloaded, if you try to use the program it will most likely not work since a number of specific libraries are required. The program notifies which are these libraries. However, for clarification they are shown below:

```
!pip install -U -q tweepy
!pip install -U -q emoji
!pip install -U PyGithub
!pip install -U -q tqdm
```

Likewise, the program's help can be accessed with the command:
`$ python Tweet_wrapper_v2.py --help`

Output:
```
Information:
    This script allows the user to collects dehydrated and hydrated tweets from
    Twitter accounts.The default Twitter accounts were selected by hand.
    Feel free for change the ones selected in this script. Tweets extractions is
    accomplish using Tweepy. Hydrated tweets are saved locally. Dehydrated tweets
    are the ones uploaded to GitHub.

    Be aware of the "Rate Limits" from Twitter. Among these limits, the number of
    tweet extraction requests is up to 450 in a temporal window of 15 minutes.
    Once the temporal windows ends, the number of requests are restarted.
    Nevertheless, the code has been developed to manage and inform about these
    temporal windows and to continue the tweets extraction.

    Morevoer, you should be aware that Twitter Policy only allows to extract
    tweets within the las 7 days (30 days for Premium API).

    The tweets collected are saved as json files. The Twitter accounts without
    tweets available for the date selected do not create json files. The information
    saved in the json files are the following ones:
        - account name
        - tweet id
        - full text (both tweet and retweet)
        - verification of the account
        - tweet date creation
        - nº of times retweeted
        - favourites count
        - tweet location (if available)
        - account url
        - tweet entities (url, hastags, etc)

Usage:
    python Tweet_wrapper_v2.py [options]

Options:
    -t, --today                  Collect tweets from today
    -d, --day                    Number of days to go back in time to collect tweets. Ex: 1 = yesterday.
    -c, --count                  Number of tweets collected per user. Directly related with computing time. Default: 200
    --git_token                  Token needed to access the Github repository where the results will be saved
    --git_repo                   Repository where you want to save the json file generated after tweet extraction
    --tweets_source_info         Information. Show the Twitter accounts used for the tweets extraction
    --git_autor                  GitHub changes author
    --git_autor_email            E-mail author
    --api_key                    CONSUMER_KEY
    --api_secret_key             CONSUMER_SECRET
    --access_token               ACCESS TOKEN
    --access_token_secret        ACCESS TOKEN SECRET

Requirements:
     -> tweepy             (pip install -U -q tweepy)
     -> emoji              (pip install -U -q emoji)
     -> github             (pip install -U -q PyGithub)
     -> tqdm               (pip install -U -q tqdm)
     -> requests_oauthlib  (pip install -U -q requests-oauthlib)

     Furthermore, you should have a GitHub account and a Twitter Developer API
     credentials.

Example. Collect up to 1000 tweets from today:
    $ python Tweet_wrapper_v2_v2.py -t -c 100 --git_token XXX --git_repo Huertas97/tweets_collection \
        --api_key XXX --api_secret_key XXX --access_token XXX --access_token_secret XXX
```
    
Also, you can consult the Twitter accounts used by:

`$ python Tweet_wrapper_v2.py --tweets_source_info `

```
Twitter accounts used by default:
['#FactCHAT', '#FakePCR', '#PCRFraude', '#VacunaRusa', '#VirusChino', '1333Despierta', '14ymedio', '20m', '24h_tve', 'AAPNewswire', 'ABCDigital', 'ABCFactCheck', 'AEMPSGOB', 'ANTIMASCARILLA', 'AP', 'ActualidadRT', 'AfricaCheck', 'Africamar', 'AlbaGar74381296', 'AmPress', 'Angelisimo2', 'AquAhora1', 'AtraviesaLoDesc', 'Autnomacabread1', 'BabylonDab', 'CDCespanol', 'CDCgov', 'CancerIntegral', 'CarmCerb21', 'CellPressNews', 'CheckCongo', 'CheckNewsfr', 'Check_Your_Fact', 'Chequeado', 'ChiguireBipolar', 'ClimateFdbk', 'Consalud_es', 'DathosBD', 'DemagogPL', 'DiegoMo53772865', 'ECUADORCHEQUEA', 'EFEVerifica', 'EFEnoticias', 'ELMINIMALISTA1', 'ElMercurio_cl', 'ElMundoBolivia', 'ElSabuesoAP', 'ElTrompetista78', 'ElUniversal', 'FDA_Drug_Info', 'FDAenEspanol', 'FDArecalls', 'FactCheckNI', 'FactCrescendo', 'FactlyIndia', 'Fatabyyano_com', 'FerretScot', 'FoxMuld88326271', 'FrayJosepho', 'FullFact', 'GlennKesslerWP', 'HayNoticia', 'HerbolarioLola', 'HomeopatiaY', 'HopkinsMedicine', 'IndiaToday', 'IsTortugo', 'JL_MDesconocido', 'JordiFlynn', 'JornalPoligrafo', 'JosPastr', 'JustiaLatinAmer', 'LANACION', 'LRsecreta', 'LaRetuerka', 'LaVozIberica', 'LaVozdelBecario', 'LogicallyAI', 'MaharatNews', 'MayoClinic', 'MediterraneoDGT', 'MiHerbolario', 'Milenio', 'Musicolorista', 'NEJM', 'NIH', 'NUnl', 'NatureComms', 'NaturopatasCol', 'NewsMeter_In', 'NewsMobileIndia', 'Newtral', 'NiusDiario', 'NoHayPandemia__', 'No__Plandemia', 'NoalaVacuna', 'ObservadorUY', 'Observateurs', 'POTUS_Trump_ESP', 'PacienteL', 'PagellaPolitica', 'Pajaropolitico', 'PericoAFuego', 'PesaCheck', 'Plandemia', 'PorunChileDigno', 'Poynter', 'ProgreAzote', 'ReutersAgency', 'ReutersLatam', 'SaludPublicaEs', 'SouthAsiaCheck', 'StopFakingNews', 'TheBabylonBee', 'TheOnion', 'TheQuint', 'The_Cling_On', 'ThipMedia', 'TrendsMolecMed', 'USATODAY', 'US_FDA', 'UniNoticias', 'VaccineSafetyN', 'VaccineXchange', 'WHO', 'YoNoMeVacuno', '_nWorder', 'abc_es', 'actualidadpanam', 'andaluciadatos', 'aosfatos', 'bbcmundo', 'boomlive_in', 'coronatimo', 'correctiv_org', 'cotejoinfo', 'covid1984', 'diariomedico', 'doctor_papaya', 'dogrulukpayicom', 'dpa', 'dubawaNG', 'el_pais', 'elcomerciocom', 'elcomerciodigit', 'eldiarioes', 'elentirvigo', 'elespectador', 'eljueves', 'elmundoes', 'elmundotoday', 'elphabaz', 'embojournal', 'estadaoverifica', 'eye_digit', 'factchecknet', 'franceinfo', 'ghana_fact', 'gonzo_blogger', 'guardiacivil', 'hermanntertsch', 'informate_infor', 'lamjort', 'laprensa', 'lasillavacia', 'ldpsincomplejos', 'lemondefr', 'maldita_ciencia', 'malditobulo', 'mediawise', 'mitokondriac', 'newsvishvas', 'nytimes', 'observadorpt', 'okdiario', 'opsoms', 'panguerrera1', 'papayaykware', 'patrilaselma', 'periodistadigit', 'policia', 'prensa_libre', 'rapplerdotcom', 'redaccionmedica', 'researchnews', 'revisbarcelona', 'sanidadgob', 'snopes', 'tecn_preocupado', 'telediario_tve', 'teyitorg', 'the_raven77', 'thecliniccl', 'thedispatch', 'thejournal_ie', 'tiramillas', 'trustdall271', 'velardedaoiz2', 'verafiles', 'yonomeconfino']
```




